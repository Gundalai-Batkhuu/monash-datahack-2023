{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa396150",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 01:09:46,800 - kedro.extras.extensions.ipython - INFO - No path argument was provided. Using: C:\\Users\\Dushku\\PycharmProjects\\monash-datahack-2023\n",
      "2023-10-10 01:09:46,929 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
      "2023-10-10 01:09:46,950 - kedro.framework.hooks.manager - INFO - Registered hooks from 1 installed plugin(s): kedro-telemetry-0.2.5\n",
      "2023-10-10 01:09:47,004 - kedro.extras.extensions.ipython - INFO - ** Kedro project Monash datahack 2023\n",
      "2023-10-10 01:09:47,005 - kedro.extras.extensions.ipython - INFO - Defined global variable `context`, `session`, `catalog` and `pipelines`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dushku\\PycharmProjects\\monash-datahack-2023\\venv\\lib\\site-packages\\kedro\\framework\\context\\context.py:344: UserWarning: Credentials not found in your Kedro project config.\n",
      "No files found in ['C:\\\\Users\\\\Dushku\\\\PycharmProjects\\\\monash-datahack-2023\\\\conf\\\\base', 'C:\\\\Users\\\\Dushku\\\\PycharmProjects\\\\monash-datahack-2023\\\\conf\\\\local'] matching the glob pattern(s): ['credentials*', 'credentials*/**', '**/credentials*']\n",
      "  warn(f\"Credentials not found in your Kedro project config.\\n{str(exc)}\")\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6952a979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 01:09:47,025 - kedro.io.data_catalog - INFO - Loading data from `preprocessed_data_not_recycled` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "df = catalog.load('preprocessed_data_not_recycled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9319cf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Jurisdiction', 'Category', 'Type', 'Management', 'Fate', 'y', 'ds',\n",
       "       'Sub_stream_name', 'Sub_stream_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95aceec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Jurisdiction', \n",
    "        'Category', \n",
    "        'Type', \n",
    "        'Management', \n",
    "        'Fate', \n",
    "        'y', \n",
    "        'Sub_stream_name',\n",
    "        'ds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa36e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33693 entries, 0 to 33692\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Jurisdiction     33693 non-null  object\n",
      " 1   Category         33693 non-null  object\n",
      " 2   Type             33693 non-null  object\n",
      " 3   Management       33693 non-null  object\n",
      " 4   Fate             33693 non-null  object\n",
      " 5   y                33693 non-null  int64 \n",
      " 6   Sub_stream_name  33693 non-null  object\n",
      " 7   ds               33693 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edfdc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "760b9b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for Jurisdiction:\n",
      "['ACT' 'NSW' 'NT' 'Qld' 'SA' 'Tas' 'Vic' 'WA']\n",
      "\n",
      "Unique values for Category:\n",
      "['Biosolids' 'Building and demolition materials' 'Hazardous wastes'\n",
      " 'Organics' 'Ash' 'Metals' 'Plastics' 'Unclassified materials'\n",
      " 'Textiles, leather & rubber (excl. tyres)']\n",
      "\n",
      "Unique values for Type:\n",
      "['Biosolids'\n",
      " 'Soil, sand and rock not contaminated above any threshold requiring classification as contaminated soils (N120)'\n",
      " 'Acids (B)' 'Alkalis (C)' 'Asbestos (N220)'\n",
      " 'Clinical and pharmaceutical (R)' 'Contaminated soils (N120)'\n",
      " 'Food-derived hazardous wastes (K100, K110)' 'Inorganic chemicals (D)'\n",
      " 'Oils (J)' 'Organic chemicals (M)' 'Organic solvents (G)' 'Other'\n",
      " 'Other hazardous organic wastes (K140, K190)'\n",
      " 'Other miscellaneous (other T)' 'Other soil/sludges (other N)'\n",
      " 'Paints, resins, inks, organic sludges (F)' 'Pesticides (H)'\n",
      " 'Plating and heat treatment (A)' 'Reactive chemicals (E)' 'Tyres (T140)'\n",
      " 'Food organics' 'Garden organics' 'Other organics' 'Timber' 'Ash'\n",
      " 'Iron and steel' 'High density polyethylene (HDPE) (2)'\n",
      " 'Unclassified materials' 'Asphalt' 'Bricks, concrete and pavers'\n",
      " 'Plasterboard & cement sheeting' 'Aluminium' 'Rubble'\n",
      " 'Low density polyethylene (LDPE) (4)' 'Other plastics (7)'\n",
      " 'Polyethylene terephthalate (PET) (1)' 'Polypropylene (PP) (5)'\n",
      " 'Polystyrene (PS) (6)' 'Polyvinyl chloride (PVC) (3)'\n",
      " 'Leather & rubber (excl. tyres)' 'Textiles']\n",
      "\n",
      "Unique values for Management:\n",
      "['Other disposal' 'Waste reuse' 'Energy from waste facility' 'Landfill'\n",
      " 'Treatment']\n",
      "\n",
      "Unique values for Fate:\n",
      "['Disposal' 'Waste reuse' 'Energy recovery' 'Long-term storage']\n",
      "\n",
      "Unique values for Sub_stream_name:\n",
      "['C&I core' 'Total' 'C&D' 'MSW' 'C&I (electricity generation)']\n",
      "\n",
      "Unique values for ds:\n",
      "['2021-12-31' '2020-12-31' '2019-12-31' '2018-12-31' '2017-12-31'\n",
      " '2016-12-31' '2015-12-31' '2014-12-31' '2013-12-31' '2012-12-31'\n",
      " '2011-12-31' '2010-12-31' '2009-12-31' '2008-12-31' '2007-12-31']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns to exclude\n",
    "exclude_columns = ['y', 'ds_encoded', ]\n",
    "\n",
    "# Create a dictionary to store unique values for each column\n",
    "unique_values_dict = {}\n",
    "\n",
    "# Loop through columns and get unique values\n",
    "for column in df.columns:\n",
    "    if column not in exclude_columns:\n",
    "        unique_values_dict[column] = df[column].unique()\n",
    "\n",
    "# Print unique values for each column\n",
    "for column, unique_values in unique_values_dict.items():\n",
    "    print(f\"Unique values for {column}:\")\n",
    "    print(unique_values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64bc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the 'date_column' to datetime and then extract the year\n",
    "df['Year'] = pd.to_datetime(df['ds']).dt.year\n",
    "df = df.drop('ds', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8e750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encoding the categorical values\n",
    "# Initialize the LabelEncoder for each categorical column\n",
    "label_encoders = {}\n",
    "\n",
    "# Columns to encode\n",
    "encode_columns = ['Jurisdiction',\n",
    "        'Sub_stream_name',\n",
    "        'Category', \n",
    "        'Type', \n",
    "        'Management', \n",
    "        'Fate']\n",
    "\n",
    "for col in encode_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    df[col] = label_encoders[col].fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0da7922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/encoders\\Jurisdiction_label_encoder.pkl\n",
      "C:/encoders\\Sub_stream_name_label_encoder.pkl\n",
      "C:/encoders\\Category_label_encoder.pkl\n",
      "C:/encoders\\Type_label_encoder.pkl\n",
      "C:/encoders\\Management_label_encoder.pkl\n",
      "C:/encoders\\Fate_label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the folder name within your project\n",
    "folder_name = '/encoders'\n",
    "\n",
    "# Create the full path to the folder\n",
    "folder_path = os.path.join(os.getcwd(), folder_name)\n",
    "\n",
    "# Ensure that the folder exists; if not, create it\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Save the LabelEncoder objects to separate files\n",
    "for col, encoder in label_encoders.items():\n",
    "    encoder_filename = f'{col}_label_encoder.pkl'\n",
    "    encoder_path = os.path.join(folder_path, encoder_filename)\n",
    "    print(encoder_path)\n",
    "    joblib.dump(encoder, encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "043026d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jurisdiction</th>\n",
       "      <th>Category</th>\n",
       "      <th>Type</th>\n",
       "      <th>Management</th>\n",
       "      <th>Fate</th>\n",
       "      <th>y</th>\n",
       "      <th>Sub_stream_name</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20186</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20186</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>133987</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>133987</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jurisdiction  Category  Type  Management  Fate       y  Sub_stream_name  \\\n",
       "0             0         1     6           2     0   20186                2   \n",
       "1             0         1     6           2     0   20186                4   \n",
       "2             0         2    37           4     3  133987                0   \n",
       "3             0         2    37           4     3  133987                4   \n",
       "4             0         3     0           0     1       0                0   \n",
       "\n",
       "   Year  \n",
       "0  2021  \n",
       "1  2021  \n",
       "2  2021  \n",
       "3  2021  \n",
       "4  2021  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c05b8848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 01:09:47,495 - kedro.io.data_catalog - INFO - Saving data to `encoded_data_not_recycled` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "catalog.save(\"encoded_data_not_recycled\", df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (monash_datahack_2023)",
   "language": "python",
   "name": "kedro_monash_datahack_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
